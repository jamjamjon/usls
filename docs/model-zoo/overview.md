# Model Zoo
***TODO***

<!-- **usls** supports a vast collection of state-of-the-art (SOTA) models for vision and vision-language tasks. All models are optimized for inference using ONNX Runtime.

## ðŸ“‚ Categories

<div class="grid cards" markdown>

-   :material-target:{ .lg .middle } __YOLO Series__

    ---

    Industry-standard models for detection, segmentation, and pose.

    [:octicons-arrow-right-24: View YOLO Models](yolo.md)

-   :material-eye-outline:{ .lg .middle } __Vision Models__

    ---

    Specialized models for SAM, RT-DETR, BiRefNet, and more.

    [:octicons-arrow-right-24: View Vision Models](vision.md)

-   :material-chat-processing-outline:{ .lg .middle } __VLM Models__

    ---

    Vision-Language models like Florence2, Moondream, and CLIP.

    [:octicons-arrow-right-24: View VLM Models](vlm.md)

</div>

## ðŸ” Model Sources

All supported ONNX models are hosted in our [ONNX Models Repository](https://github.com/jamjamjon/assets). **usls** handles the downloading and caching of these models automatically.

## ðŸ“Š Status Legend

| Symbol | Meaning |
| :---: | :--- |
| âœ… | **Fully Supported**: Tested and verified. |
| â“ | **Unknown**: Likely works but not strictly verified. |
| âŒ | **Planned**: Support is on the roadmap. |

---

*Don't see a model you need? Open a [feature request](https://github.com/jamjamjon/usls/issues).* -->
